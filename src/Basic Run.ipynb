{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import run_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from download_naips import NAIPDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIP /DeepOSM/data/naip/m_3807708_ne_18_1_20130924.tif already downloaded\n",
      "NAIP /DeepOSM/data/naip/m_3807708_nw_18_1_20130904.tif already downloaded\n",
      "NAIP /DeepOSM/data/naip/m_3807708_se_18_1_20130924.tif already downloaded\n",
      "NAIP /DeepOSM/data/naip/m_3807708_se_18_1_20130924.tif already downloaded\n"
     ]
    }
   ],
   "source": [
    "raster_data_paths = NAIPDownloader(NUMBER_OF_NAIPS,\n",
    "                                 RANDOMIZE_NAIPS,\n",
    "                                 NAIP_STATE,\n",
    "                                 NAIP_YEAR,\n",
    "                                 NAIP_RESOLUTION,\n",
    "                                 NAIP_SPECTRUM,\n",
    "                                 NAIP_GRID,\n",
    "                                 HARDCODED_NAIP_LIST).download_naips()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOADING 3 PBFs...\n",
      "PBF /DeepOSM/data/maryland-latest.osm.pbf already downloaded\n",
      "PBF /DeepOSM/data/virginia-latest.osm.pbf already downloaded\n",
      "PBF /DeepOSM/data/district-of-columbia-latest.osm.pbf already downloaded\n",
      "EXTRACTED WAYS with locations from pbf file /DeepOSM/data/maryland-latest.osm.pbf, took 30.8s\n",
      "EXTRACTED WAYS with locations from pbf file /DeepOSM/data/virginia-latest.osm.pbf, took 52.3s\n",
      "EXTRACTED WAYS with locations from pbf file /DeepOSM/data/district-of-columbia-latest.osm.pbf, took 5.3s\n",
      "FINDING WAYS on NAIP...  0.0s\n",
      "EXTRACTED 39 highways in NAIP bounds, of 3666 ways\n",
      "MAKING BITMAP for way presence...  1.9s\n",
      "OPENED NAIP with 7659 rows, 6171 cols, and 2 bands\n",
      "GEO-BOUNDS for image chunk is {'sw': (38.93364288504744, -77.06585248141359), 'ne': (39.003857347769674, -76.99663397248327)}\n",
      "FINDING WAYS on NAIP...  0.0s\n",
      "EXTRACTED 86 highways in NAIP bounds, of 3666 ways\n",
      "MAKING BITMAP for way presence...  4.0s\n",
      "OPENED NAIP with 7662 rows, 6176 cols, and 2 bands\n",
      "GEO-BOUNDS for image chunk is {'sw': (38.933609784870235, -77.1283537217638), 'ne': (39.003887709853196, -77.05914175201985)}\n",
      "FINDING WAYS on NAIP...  0.0s\n",
      "EXTRACTED 36 highways in NAIP bounds, of 3666 ways\n",
      "MAKING BITMAP for way presence...  1.7s\n",
      "OPENED NAIP with 7658 rows, 6175 cols, and 2 bands\n",
      "GEO-BOUNDS for image chunk is {'sw': (38.87114775884972, -77.06585109684843), 'ne': (38.94135310183272, -76.99664430802693)}\n",
      "FINDING WAYS on NAIP...  0.0s\n",
      "EXTRACTED 36 highways in NAIP bounds, of 3666 ways\n",
      "MAKING BITMAP for way presence...  1.7s\n",
      "OPENED NAIP with 7658 rows, 6175 cols, and 2 bands\n",
      "GEO-BOUNDS for image chunk is {'sw': (38.87114775884972, -77.06585109684843), 'ne': (38.94135310183272, -76.99664430802693)}\n"
     ]
    }
   ],
   "source": [
    "road_labels, naip_tiles, waymap, way_bitmap_npy = run_analysis.random_training_data(raster_data_paths, cache_way_bmp=False, extract_type='tennis')\n",
    "equal_count_way_list, equal_count_tile_list = run_analysis.equalize_data(road_labels, naip_tiles)\n",
    "test_labels, training_labels, test_images, training_images = run_analysis.split_train_test(equal_count_tile_list,equal_count_way_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING/TEST DATA: shaped the tiff data to 1020 tiles sized 64 x 64 with 2 bands\n",
      "CREATING ONE-HOT LABELS...\n",
      "CREATING TEST one-hot labels\n",
      "ONE-HOT labels: 19 on, 19 off (50.0% on)\n",
      "CREATING TRAINING one-hot labels\n",
      "ONE-HOT labels: 255 on, 255 off (50.0% on)\n",
      "one-hotting took 0.8s\n",
      "CREATED DATASET: 510 training images, 38 test images, with 510 training labels, and 38 test labels\n",
      "TRAINING...\n",
      "step 0, loss = 749.227416992, loss rolling avg = 749.227416992 \n",
      "step 1, loss = 613.463928223, loss rolling avg = 681.345672607 \n",
      "step 2, loss = 506.816864014, loss rolling avg = 623.169403076 \n",
      "step 3, loss = 74.0390625, loss rolling avg = 485.886817932 \n",
      "step 4, loss = 394.246459961, loss rolling avg = 467.558746338 \n",
      "step 5, loss = 343.944396973, loss rolling avg = 446.956354777 \n",
      "step 6, loss = 53.5878677368, loss rolling avg = 390.760856628 \n",
      "step 7, loss = 279.995605469, loss rolling avg = 376.915200233 \n",
      "step 8, loss = 267.979644775, loss rolling avg = 364.811249627 \n",
      "step 9, loss = 75.9115142822, loss rolling avg = 335.921276093 \n",
      "step 10, loss = 216.834030151, loss rolling avg = 325.095162825 \n",
      "step 11, loss = 251.92175293, loss rolling avg = 318.997378667 \n",
      "step 12, loss = 91.6709747314, loss rolling avg = 301.510732211 \n",
      "step 13, loss = 206.208496094, loss rolling avg = 294.703429631 \n",
      "step 14, loss = 199.390899658, loss rolling avg = 288.349260966 \n",
      "step 15, loss = 174.991394043, loss rolling avg = 281.264394283 \n",
      "step 16, loss = 111.414466858, loss rolling avg = 271.273222082 \n",
      "step 17, loss = 193.494979858, loss rolling avg = 266.952208625 \n",
      "step 18, loss = 86.3751220703, loss rolling avg = 257.448151438 \n",
      "step 19, loss = 83.1665039062, loss rolling avg = 248.734069061 \n",
      "step 20, loss = 120.094551086, loss rolling avg = 242.608377729 \n",
      "step 21, loss = 125.273460388, loss rolling avg = 237.274972395 \n",
      "step 22, loss = 76.6488342285, loss rolling avg = 230.291227258 \n",
      "step 23, loss = 134.908706665, loss rolling avg = 226.316955566 \n",
      "step 24, loss = 72.4105148315, loss rolling avg = 220.160697937 \n",
      "step 25, loss = 70.6468963623, loss rolling avg = 214.410167107 \n",
      "step 26, loss = 57.7460174561, loss rolling avg = 208.607791194 \n",
      "step 27, loss = 69.2985076904, loss rolling avg = 203.632459641 \n",
      "step 28, loss = 73.5207672119, loss rolling avg = 199.145849557 \n",
      "step 29, loss = 45.7356719971, loss rolling avg = 194.032176971 \n",
      "step 30, loss = 62.1216773987, loss rolling avg = 189.776999566 \n",
      "step 31, loss = 52.3411827087, loss rolling avg = 185.482130289 \n",
      "step 32, loss = 53.9357910156, loss rolling avg = 181.495877584 \n",
      "step 33, loss = 49.9418334961, loss rolling avg = 177.626640993 \n",
      "step 34, loss = 54.6467895508, loss rolling avg = 174.112930952 \n",
      "step 35, loss = 55.0671539307, loss rolling avg = 170.806103812 \n",
      "step 36, loss = 45.6036643982, loss rolling avg = 167.422254098 \n",
      "step 37, loss = 60.0709648132, loss rolling avg = 164.59722017 \n",
      "step 38, loss = 69.0453948975, loss rolling avg = 162.147173368 \n",
      "step 39, loss = 48.268535614, loss rolling avg = 159.300207424 \n",
      "step 40, loss = 57.1423416138, loss rolling avg = 156.80855216 \n",
      "step 41, loss = 59.5912246704, loss rolling avg = 154.493853887 \n",
      "step 42, loss = 50.4549560547, loss rolling avg = 152.074344635 \n",
      "step 43, loss = 72.4369659424, loss rolling avg = 150.26440421 \n",
      "step 44, loss = 36.9630737305, loss rolling avg = 147.746596866 \n",
      "step 45, loss = 60.4794769287, loss rolling avg = 145.849485563 \n",
      "step 46, loss = 41.1460838318, loss rolling avg = 143.621753611 \n",
      "step 47, loss = 64.0106658936, loss rolling avg = 141.963189284 \n",
      "step 48, loss = 50.7989501953, loss rolling avg = 140.102694609 \n",
      "step 49, loss = 65.3147888184, loss rolling avg = 138.606936493 \n",
      "step 50, loss = 47.855506897, loss rolling avg = 136.827496697 \n",
      "step 51, loss = 53.8079605103, loss rolling avg = 135.230967155 \n",
      "step 52, loss = 57.5797996521, loss rolling avg = 133.765850787 \n",
      "step 53, loss = 56.0142555237, loss rolling avg = 132.32600643 \n",
      "step 54, loss = 29.8718490601, loss rolling avg = 130.463203569 \n",
      "step 55, loss = 39.9821357727, loss rolling avg = 128.847470215 \n",
      "step 56, loss = 36.0201950073, loss rolling avg = 127.218921528 \n",
      "step 57, loss = 46.5511322021, loss rolling avg = 125.828097574 \n",
      "step 58, loss = 48.5823974609, loss rolling avg = 124.518848419 \n",
      "step 59, loss = 56.8495941162, loss rolling avg = 123.391027514 \n",
      "step 60, loss = 35.0075531006, loss rolling avg = 121.942118098 \n",
      "step 61, loss = 40.1587524414, loss rolling avg = 120.623031555 \n",
      "step 62, loss = 32.5433654785, loss rolling avg = 119.224941617 \n",
      "step 63, loss = 27.7968387604, loss rolling avg = 117.79637751 \n",
      "step 64, loss = 50.4247894287, loss rolling avg = 116.759891539 \n",
      "step 65, loss = 39.1813812256, loss rolling avg = 115.584459565 \n",
      "step 66, loss = 48.1828651428, loss rolling avg = 114.578465618 \n",
      "step 67, loss = 37.5299949646, loss rolling avg = 113.445399873 \n",
      "step 68, loss = 42.5094299316, loss rolling avg = 112.417342338 \n",
      "step 69, loss = 41.6063652039, loss rolling avg = 111.40575695 \n",
      "step 70, loss = 29.0687713623, loss rolling avg = 110.246081097 \n",
      "step 71, loss = 54.0808563232, loss rolling avg = 109.466008531 \n",
      "step 72, loss = 59.7009086609, loss rolling avg = 108.784294834 \n",
      "step 73, loss = 54.4481773376, loss rolling avg = 108.050022976 \n",
      "step 74, loss = 45.9019165039, loss rolling avg = 107.221381556 \n",
      "step 75, loss = 29.94556427, loss rolling avg = 106.204594487 \n",
      "step 76, loss = 29.950756073, loss rolling avg = 105.214284897 \n",
      "step 77, loss = 65.3851394653, loss rolling avg = 104.703654827 \n",
      "step 78, loss = 30.274187088, loss rolling avg = 103.761509666 \n",
      "step 79, loss = 64.5636749268, loss rolling avg = 103.271536732 \n",
      "step 80, loss = 26.9866600037, loss rolling avg = 102.32974813 \n",
      "step 81, loss = 78.7404327393, loss rolling avg = 102.042073552 \n",
      "step 82, loss = 47.0342178345, loss rolling avg = 101.379328303 \n",
      "step 83, loss = 28.4423408508, loss rolling avg = 100.511030833 \n",
      "step 84, loss = 82.208732605, loss rolling avg = 100.295709677 \n",
      "step 85, loss = 34.0529327393, loss rolling avg = 99.5254448292 \n",
      "step 86, loss = 69.3368988037, loss rolling avg = 99.1784500473 \n",
      "step 87, loss = 35.2832183838, loss rolling avg = 98.4523678693 \n",
      "step 88, loss = 70.6905670166, loss rolling avg = 98.1404375226 \n",
      "step 89, loss = 37.1897735596, loss rolling avg = 97.463207923 \n",
      "step 90, loss = 51.1513824463, loss rolling avg = 96.954286764 \n",
      "step 91, loss = 64.5043182373, loss rolling avg = 96.6015697148 \n",
      "step 92, loss = 47.1853065491, loss rolling avg = 96.0702120463 \n",
      "step 93, loss = 61.6504516602, loss rolling avg = 95.7040443826 \n",
      "step 94, loss = 28.8222370148, loss rolling avg = 95.0000253577 \n",
      "step 95, loss = 51.1997718811, loss rolling avg = 94.5437727173 \n",
      "step 96, loss = 47.7400817871, loss rolling avg = 94.0612604397 \n",
      "step 97, loss = 25.9342708588, loss rolling avg = 93.3660870766 \n",
      "step 98, loss = 34.0413970947, loss rolling avg = 92.7668477839 \n",
      "step 99, loss = 23.4551105499, loss rolling avg = 92.0737304115 \n",
      "step 100, loss = 35.0464553833, loss rolling avg = 91.5091039261 \n",
      "step 101, loss = 30.3961410522, loss rolling avg = 90.9099572313 \n",
      "step 102, loss = 22.9918079376, loss rolling avg = 90.2505577236 \n",
      "step 103, loss = 30.2029628754, loss rolling avg = 89.6731770039 \n",
      "step 104, loss = 32.5115661621, loss rolling avg = 89.1287807101 \n",
      "step 105, loss = 30.2033863068, loss rolling avg = 88.5728807629 \n",
      "step 106, loss = 32.9876174927, loss rolling avg = 88.0533923211 \n",
      "step 107, loss = 30.3968448639, loss rolling avg = 87.5195354002 \n",
      "step 108, loss = 19.7903594971, loss rolling avg = 86.898166814 \n",
      "step 109, loss = 26.4868011475, loss rolling avg = 86.3489725806 \n",
      "step 110, loss = 20.0983905792, loss rolling avg = 85.7521204905 \n",
      "step 111, loss = 61.4293518066, loss rolling avg = 85.534952913 \n",
      "step 112, loss = 18.9833946228, loss rolling avg = 84.9460010697 \n",
      "step 113, loss = 27.038351059, loss rolling avg = 84.4380392275 \n",
      "step 114, loss = 21.2021560669, loss rolling avg = 83.8881619827 \n",
      "step 115, loss = 38.7854804993, loss rolling avg = 83.499345763 \n",
      "step 116, loss = 25.99883461, loss rolling avg = 83.0078884027 \n",
      "step 117, loss = 31.904712677, loss rolling avg = 82.5748106423 \n",
      "step 118, loss = 37.936126709, loss rolling avg = 82.1996956513 \n",
      "step 119, loss = 29.7689666748, loss rolling avg = 81.7627729098 \n",
      "step 120, loss = 32.0417289734, loss rolling avg = 81.3518551913 \n",
      "step 121, loss = 31.0017490387, loss rolling avg = 80.9391494032 \n",
      "step 122, loss = 26.2316417694, loss rolling avg = 80.4943729184 \n",
      "step 123, loss = 46.9374275208, loss rolling avg = 80.223752391 \n",
      "step 124, loss = 22.8799419403, loss rolling avg = 79.7650019073 \n",
      "step 125, loss = 55.8913192749, loss rolling avg = 79.5755282357 \n",
      "step 126, loss = 43.6604232788, loss rolling avg = 79.2927321336 \n",
      "step 127, loss = 54.8035507202, loss rolling avg = 79.1014104038 \n",
      "step 128, loss = 30.9337749481, loss rolling avg = 78.7280178809 \n",
      "step 129, loss = 19.3571720123, loss rolling avg = 78.2713190666 \n",
      "step 130, loss = 24.2227573395, loss rolling avg = 77.8587346259 \n",
      "step 131, loss = 23.0332336426, loss rolling avg = 77.4433899215 \n",
      "step 132, loss = 21.8900508881, loss rolling avg = 77.025695643 \n",
      "step 133, loss = 22.0447006226, loss rolling avg = 76.61538971 \n",
      "step 134, loss = 16.4997806549, loss rolling avg = 76.1700889022 \n",
      "step 135, loss = 25.9774284363, loss rolling avg = 75.8010252223 \n",
      "step 136, loss = 35.4818916321, loss rolling avg = 75.5067249771 \n",
      "step 137, loss = 44.6559791565, loss rolling avg = 75.283168848 \n",
      "step 138, loss = 38.5625038147, loss rolling avg = 75.0189914017 \n",
      "step 139, loss = 34.1663551331, loss rolling avg = 74.727186857 \n",
      "step 140, loss = 41.5090065002, loss rolling avg = 74.4915969253 \n",
      "step 141, loss = 15.0511083603, loss rolling avg = 74.0730019354 \n",
      "step 142, loss = 39.5267524719, loss rolling avg = 73.8314197714 \n",
      "step 143, loss = 23.2112007141, loss rolling avg = 73.4798904724 \n",
      "step 144, loss = 13.4526119232, loss rolling avg = 73.065909241 \n",
      "step 145, loss = 45.6984291077, loss rolling avg = 72.8784607469 \n",
      "step 146, loss = 20.2476043701, loss rolling avg = 72.5204277103 \n",
      "step 147, loss = 36.1125831604, loss rolling avg = 72.2744287607 \n",
      "step 148, loss = 24.3475379944, loss rolling avg = 71.9527717757 \n",
      "step 149, loss = 17.7262306213, loss rolling avg = 71.5912615013 \n",
      "step 150, loss = 20.2240486145, loss rolling avg = 71.2510812835 \n",
      "step 151, loss = 18.4420909882, loss rolling avg = 70.9036537158 \n",
      "step 152, loss = 22.260799408, loss rolling avg = 70.5857265634 \n",
      "step 153, loss = 22.312959671, loss rolling avg = 70.2722670382 \n",
      "step 154, loss = 15.7428512573, loss rolling avg = 69.9204643557 \n",
      "step 155, loss = 15.1044540405, loss rolling avg = 69.5690796742 \n",
      "step 156, loss = 22.4078464508, loss rolling avg = 69.2686896537 \n",
      "step 157, loss = 26.1971607208, loss rolling avg = 68.9960850402 \n",
      "step 158, loss = 17.0268859863, loss rolling avg = 68.6692347317 \n",
      "step 159, loss = 12.9481258392, loss rolling avg = 68.3209778011 \n",
      "step 160, loss = 11.8945713043, loss rolling avg = 67.9705032266 \n",
      "step 161, loss = 25.8684024811, loss rolling avg = 67.7106137158 \n",
      "step 162, loss = 16.577255249, loss rolling avg = 67.3969121301 \n",
      "step 163, loss = 41.6062927246, loss rolling avg = 67.2396522557 \n",
      "step 164, loss = 20.8044242859, loss rolling avg = 66.9582266316 \n",
      "step 165, loss = 34.0686531067, loss rolling avg = 66.7600966706 \n",
      "step 166, loss = 18.1401290894, loss rolling avg = 66.4689591402 \n",
      "step 167, loss = 25.0026836395, loss rolling avg = 66.2221360718 \n",
      "step 168, loss = 27.0852508545, loss rolling avg = 65.9905568693 \n",
      "step 169, loss = 15.1762924194, loss rolling avg = 65.6916494313 \n",
      "step 170, loss = 45.5253829956, loss rolling avg = 65.5737180487 \n",
      "step 171, loss = 11.5493993759, loss rolling avg = 65.2596231727 \n",
      "step 172, loss = 20.5129165649, loss rolling avg = 65.0009716894 \n",
      "step 173, loss = 30.163274765, loss rolling avg = 64.8007550404 \n",
      "step 174, loss = 28.4155082703, loss rolling avg = 64.5928393446 \n",
      "step 175, loss = 42.229511261, loss rolling avg = 64.4657749805 \n",
      "step 176, loss = 18.586227417, loss rolling avg = 64.206568497 \n",
      "step 177, loss = 48.6692619324, loss rolling avg = 64.1192802579 \n",
      "step 178, loss = 18.7760887146, loss rolling avg = 63.8659663387 \n",
      "step 179, loss = 38.953327179, loss rolling avg = 63.7275627878 \n",
      "step 180, loss = 33.3976593018, loss rolling avg = 63.5599942603 \n",
      "step 181, loss = 14.2417402267, loss rolling avg = 63.2890148425 \n",
      "step 182, loss = 44.033744812, loss rolling avg = 63.1837947877 \n",
      "step 183, loss = 16.8444633484, loss rolling avg = 62.9319505951 \n",
      "step 184, loss = 21.2756347656, loss rolling avg = 62.7067813203 \n",
      "step 185, loss = 18.9575576782, loss rolling avg = 62.4715704405 \n",
      "step 186, loss = 7.84986257553, loss rolling avg = 62.1794757461 \n",
      "step 187, loss = 39.7411727905, loss rolling avg = 62.0601230708 \n",
      "step 188, loss = 9.8359336853, loss rolling avg = 61.7838046084 \n",
      "step 189, loss = 28.849565506, loss rolling avg = 61.6104665079 \n",
      "step 190, loss = 9.74624252319, loss rolling avg = 61.3389260682 \n",
      "step 191, loss = 10.9213695526, loss rolling avg = 61.076334628 \n",
      "step 192, loss = 18.2700023651, loss rolling avg = 60.8545401603 \n",
      "step 193, loss = 10.3374404907, loss rolling avg = 60.5941427393 \n",
      "step 194, loss = 17.4016036987, loss rolling avg = 60.3726425391 \n",
      "step 195, loss = 14.5945396423, loss rolling avg = 60.1390807896 \n",
      "step 196, loss = 11.3956203461, loss rolling avg = 59.8916520564 \n",
      "step 197, loss = 11.4948768616, loss rolling avg = 59.6472238989 \n",
      "step 198, loss = 15.1185817719, loss rolling avg = 59.4234618781 \n",
      "step 199, loss = 16.9727706909, loss rolling avg = 59.2112084222 \n",
      "training time 722.0s\n",
      "test accuracy 0.578947\n"
     ]
    }
   ],
   "source": [
    "predictions = run_analysis.analyze(test_labels, training_labels, test_images, training_images, waymap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING JPEG for /DeepOSM/data/naip/m_3807708_ne_18_1_20130924.tif\n",
      "6.4s to FLATTEN the 2 analyzed bands of TIF to JPEG\n",
      "0.1s to SHADE PREDICTIONS on JPEG\n",
      "13.2s to DRAW WAYS ON JPEG\n",
      "GENERATING JPEG for /DeepOSM/data/naip/m_3807708_nw_18_1_20130904.tif\n",
      "5.8s to FLATTEN the 2 analyzed bands of TIF to JPEG\n",
      "0.1s to SHADE PREDICTIONS on JPEG\n",
      "13.3s to DRAW WAYS ON JPEG\n",
      "GENERATING JPEG for /DeepOSM/data/naip/m_3807708_se_18_1_20130924.tif\n",
      "5.2s to FLATTEN the 2 analyzed bands of TIF to JPEG\n",
      "0.2s to SHADE PREDICTIONS on JPEG\n",
      "13.2s to DRAW WAYS ON JPEG\n",
      "GENERATING JPEG for /DeepOSM/data/naip/m_3807708_se_18_1_20130924.tif\n",
      "3.9s to FLATTEN the 2 analyzed bands of TIF to JPEG\n",
      "0.2s to SHADE PREDICTIONS on JPEG\n",
      "13.1s to DRAW WAYS ON JPEG\n"
     ]
    }
   ],
   "source": [
    "run_analysis.render_results_as_images(raster_data_paths, training_labels, test_labels, predictions, way_bitmap_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
